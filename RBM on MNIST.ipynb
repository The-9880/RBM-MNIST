{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow: 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"Tensorflow: {}\".format(tf.VERSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll load the dataset and inspect it a little - I have two approaches in mind, both of which involve scaling pixel intensities down to [0, 1]:\n",
    "1) Threshold pixel classes at 0.5 - <0.5 is white, >0.5 is black\n",
    "2) Treat the pixel intensities as the likelihood of activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:  60000\n",
      "Training set shape:  (60000, 28, 28)\n",
      "Test cases:  10000\n",
      "Training shape:  (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24dd8a436d8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, test = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "# Quick check on the sizes of the datasets\n",
    "print(\"Training samples: \", len(train[0]))\n",
    "print(\"Training set shape: \", train[0].shape)\n",
    "print(\"Test cases: \", len(test[0]))\n",
    "\n",
    "# Checking the size of each sample\n",
    "print(\"Training shape: \", train[0][0].shape)\n",
    "\n",
    "# print(train[0][0]) -- examining the values; 0-255\n",
    "\n",
    "# Checking out a sample\n",
    "image = train[0][0]\n",
    "plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "plt.show()\n",
    "\n",
    "# Copying the sample, thresholding activations at >0.5 == 1, <0.5 == 0\n",
    "example = train[0][0]\n",
    "example = example / 255.0\n",
    "\n",
    "for i, x in enumerate(example):\n",
    "    for j, y in enumerate(x):\n",
    "        if y < 0.5:\n",
    "            example[i][j] = 0\n",
    "        else:\n",
    "            example[i][j] = 1\n",
    "\n",
    "f, axarr = plt.subplots(1, 2)\n",
    "axarr[0].imshow(image)\n",
    "axarr[1].imshow(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM():\n",
    "    def __init__(self, v_units=784, h_units=200, k_steps=35):\n",
    "        self.num_visible = v_units # visible units\n",
    "        self.num_hidden = h_units # hidden units\n",
    "        self.k_steps = k_steps # k-steps for contrastive divergence\n",
    "        \n",
    "        self.alpha = tf.Variable(0.1) # learning rate\n",
    "        \n",
    "        # RBM architecture will be two layers only - visible and hidden, none else; not a DBM\n",
    "        self.weights = tf.Variable(tf.truncated_normal(shape=[self.num_visible, self.num_hidden], stddev=0.1), name='weights')\n",
    "        self.v_biases = tf.Variable(tf.constant(1.0, shape=[self.num_visible]), name='visible_biases')\n",
    "        self.h_biases = tf.Variable(tf.constant(1.0, shape=[self.num_hidden]), name='hidden_biases')\n",
    "        \n",
    "    def vhActivation(self, visible):\n",
    "        # We use the result of sigmoid activation as the probability of neuron firing\n",
    "        input = tf.matmul(visible, self.weights) + self.h_biases\n",
    "        return tf.nn.sigmoid(input)\n",
    "    \n",
    "    def hvActivation(self, hidden):\n",
    "        # Same case, in reverse\n",
    "        input = tf.matmul(hidden, tf.transpose(self.weights)) + self.v_biases\n",
    "        return tf.nn.sigmoid(input)\n",
    "    \n",
    "    # Two following functions are Gibbs sampling steps\n",
    "    # To simulate the firing of stochastic binary neurons, we make use of tf.random_uniform\n",
    "    # which generates random vals between [0, 1) for floats. As they are random,\n",
    "    # we don't know which are larger/smaller than the sigmoid activations.\n",
    "    # So we subtract them from the sigmoid activations and then use ReLU to decide which neurons have fired 'stochastically'\n",
    "    # and which haven't. tf.sign raises the values that would survive to 1, and drops the losing neurons to -1 to be culled by ReLU\n",
    "    def sample_h(self, v_sample):\n",
    "        h = self.vhActivation(v_sample)\n",
    "        h_sample = tf.nn.relu(tf.sign(h - tf.random_uniform(tf.shape(h))))\n",
    "        return h_sample\n",
    "    \n",
    "    def sample_v(self, h_sample):\n",
    "        v = self.hvActivation(h_sample)\n",
    "        v_sample = tf.nn.relu(tf.sign(v - tf.random_uniform(tf.shape(v))))\n",
    "        return v_sample\n",
    "    \n",
    "    # CDk learning algorithm\n",
    "    def CD_k(self, v):\n",
    "        # sample with k steps of Gibbs\n",
    "        v_sample = v\n",
    "        h_sample = self.sample_h(v_sample) # generating the first step in the Markov chain from time t=0\n",
    "        \n",
    "        for step in range(self.k_steps): # subsequent time steps in the Markov chain progress now for k steps\n",
    "            v_sample = self.sample_v(h_sample)\n",
    "            h_sample = self.sample_h(v_sample)\n",
    "        \n",
    "        # The learning rule is ΔW = ε(<vh>0 - <vh>k)\n",
    "        # in <vh>0, v is the visible vector at the beginning of the Markov particle, h is sample generated given that v.\n",
    "        # in <vh>k, the last sampling taken from the chain, v and h are both final samples generated from the chain\n",
    "        h = self.vhActivation(v)\n",
    "        positive_statistic = tf.matmul(tf.transpose(v), h) # wish to increase probability of the visible vector\n",
    "        negative_statistic = tf.matmul(tf.transpose(v_sample), h_sample) # decrease probabilities of competing vectors\n",
    "        w_grad = (positive_statistic - negative_statistic) / tf.to_float(tf.shape(v)[0])\n",
    "        \n",
    "        # in keeping with the guides I'm following, I'll perform these next two steps.\n",
    "        # They look to be gradients for the biases\n",
    "        hb_grad = tf.reduce_mean(h - h_sample, 0)\n",
    "        vb_grad = tf.reduce_mean(v - v_sample, 0)\n",
    "        \n",
    "        return w_grad, hb_grad, vb_grad\n",
    "    \n",
    "    def learning_step(self, v):\n",
    "        w_grad, hb_grad, vb_grad = self.CD_k(v)\n",
    "        \n",
    "        w = tf.assign(self.weights, self.alpha * w_grad)\n",
    "        hb = tf.assign(self.h_biases, self.alpha * hb_grad)\n",
    "        vb = tf.assign(self.v_biases, self.alpha * vb_grad)\n",
    "        return [w, vb, hb]\n",
    "    \n",
    "    # function to get samples of reconstructed images from the model\n",
    "    # run for a number of steps to approach the stationary distribution of the model\n",
    "    # then return a reconstruction to display\n",
    "    def imageSample(self, v, steps=5000):\n",
    "        v_sample = v\n",
    "        # Run chain for 'steps' iterations before taking a sample - default is 5000 steps\n",
    "        for step in range(steps):\n",
    "            v_sample = self.sample_v(self.sample_h((v_sample)))\n",
    "        return v_sample\n",
    "    \n",
    "    # Functions for calculating likelihood now follow\n",
    "    # Our objective function is to maximize the likelihood of visible vectors from the dataset\n",
    "    # while reducing the likelihood of competitor vectors\n",
    "    # to track this, we try to quantify the log probabilities\n",
    "    # but because the amount of join configurations of (v, h) vary exponentially with the number of units,\n",
    "    # we compute approximations instead; pseudo likelihood.\n",
    "    def free_energy(self, v):\n",
    "        # (1 x num_visible) * (num_visible x 1) -> real value output\n",
    "        print(v.get_shape())\n",
    "        print(self.v_biases.get_shape())\n",
    "        visible_activations = tf.matmul(v, tf.reshape(self.v_biases, [tf.shape(self.v_biases)[0], 1]))\n",
    "        # visible activations took care of energy contributions from the visible units and their biases\n",
    "        # activations within the hidden layer, including visible-hidden contributions, are exponentiated\n",
    "        # and marginalized in the logarithmic domain\n",
    "        activations = tf.reduce_sum(tf.log(1 + tf.exp(self.h_biases + tf.matmul(v, self.weights))), axis=1)\n",
    "        return -(visible_activations - activations)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    def pseudo_log_likelihood(self, v):\n",
    "        vec = tf.round(v)\n",
    "        vec_fe = self.free_energy(vec)\n",
    "        split0, split1, split2 = tf.split(vec, [self.i, 1, tf.shape(vec)[1] - self.i - 1], 1)\n",
    "        veci = tf.concat([split0, 1 - split1, split2], 1)\n",
    "        self.i = (self.i + 1) % self.num_visible\n",
    "        veci_fe = self.free_energy(veci)\n",
    "        return tf.reduce_mean(self.num_visible * tf.log(tf.nn.sigmoid(veci_fe - vec_fe)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def trainRBM(training_data, test_data, epochs):\n",
    "    \n",
    "    data = np.float32(np.reshape(training_data, [60000, 784]))\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    \n",
    "    rbm = RBM()\n",
    "    rbm.alpha = 0.1\n",
    "    \n",
    "    step = rbm.learning_step(x)\n",
    "    sampler = rbm.imageSample(x)\n",
    "    pl = rbm.pseudo_log_likelihood(x)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        mean_cost = [] # averaging cost over 500 epochs\n",
    "        for i in range(epochs):\n",
    "            cost = sess.run(pl, feed_dict={x: data} )\n",
    "            mean_cost.append(cost)\n",
    "\n",
    "            # draw a sample every 500 epochs\n",
    "            if i % 500 == 0:\n",
    "                sample = sess.run(sampler, feed_dict = {x: data})\n",
    "                sample = sample[random.randrange(59999)].reshape([28, 28])\n",
    "                plt.imshow(sample, cmap=plt.get_cmap('gray_r'))\n",
    "                print('Epoch ', i+1, ', Cost: ', np.mean(mean_cost))\n",
    "                mean_cost = []\n",
    "\n",
    "        print('Test data')\n",
    "        testCase = random.randrange(9999)\n",
    "        sample = sess.run(sampler, feed_dict = {x: test_data[testCase]})\n",
    "        sample = sample.reshape([28, 28])\n",
    "        plt.title(\"Label: %d\" % test[1][testCase])\n",
    "        plt.imshow(sample)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.  18.\n",
      "   18.  18. 126. 136. 175.  26. 166. 255. 247. 127.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.  30.  36.  94. 154. 170. 253.\n",
      "  253. 253. 253. 253. 225. 172. 253. 242. 195.  64.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.  49. 238. 253. 253. 253. 253. 253.\n",
      "  253. 253. 253. 251.  93.  82.  82.  56.  39.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.  18. 219. 253. 253. 253. 253. 253.\n",
      "  198. 182. 247. 241.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.  80. 156. 107. 253. 253. 205.\n",
      "   11.   0.  43. 154.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.  14.   1. 154. 253.  90.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 139. 253. 190.\n",
      "    2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  11. 190. 253.\n",
      "   70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  35. 241.\n",
      "  225. 160. 108.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  81.\n",
      "  240. 253. 253. 119.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   45. 186. 253. 253. 150.  27.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.  16.  93. 252. 253. 187.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0. 249. 253. 249.  64.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   46. 130. 183. 253. 253. 207.   2.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  39. 148.\n",
      "  229. 253. 253. 253. 250. 182.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  24. 114. 221. 253.\n",
      "  253. 253. 253. 201.  78.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.  23.  66. 213. 253. 253. 253.\n",
      "  253. 198.  81.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.  18. 171. 219. 253. 253. 253. 253. 195.\n",
      "   80.   9.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.  55. 172. 226. 253. 253. 253. 253. 244. 133.  11.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0. 136. 253. 253. 253. 212. 135. 132.  16.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "trainRBM(train[0], test[0], 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
