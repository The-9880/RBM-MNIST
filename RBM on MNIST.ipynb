{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow: 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"Tensorflow: {}\".format(tf.VERSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll load the dataset and inspect it a little - I have two approaches in mind, both of which involve scaling pixel intensities down to [0, 1]:\n",
    "1) Threshold pixel classes at 0.5 - <0.5 is white, >0.5 is black\n",
    "2) Treat the pixel intensities as the likelihood of activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:  60000\n",
      "Training set shape:  (60000, 28, 28)\n",
      "Test cases:  10000\n",
      "Training shape:  (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1db4da77908>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAD0xJREFUeJzt3X+QVfV5x/HPJ7BAEZJADRQNEUowmmiDzRZ1dIgZqxInM+q01tBMxqTpkGpItKVTqdOpNqMd0klsjbXOQCXgjD8So1amY2MZxlHTKhWpUQgqBqlBNkuQUdAoP5anf3DpbDln2fvjnHvv+e77NcPcu89+7z3P2X14OJzv99zjiBAAoPre1+kEAADFoKEDQCJo6ACQCBo6ACSChg4AiaChA0AiaOgAkAgaOgAkoqWGbnu+7Zdsv2J7SVFJAZ1GbaOK3OyVorZHSXpZ0gWStkt6RtKCiPhpcekB7Udto6pGt/DauZJeiYitkmT7PkmXSBqy6Md4bIzTcS1sEhjae3pH+2OfC3grahtdpd7abqWhnyjp54O+3i7pzGO9YJyO05k+v4VNAkNbF2uLeitqG12l3tpupaHn/WuROX9je6GkhZI0TuNb2BzQNtQ2KqmVSdHtkqYP+vrDknYcPSgilkVEb0T09mhsC5sD2obaRiW10tCfkTTb9kzbYyR9XtLqYtICOoraRiU1fcolIg7aXiTpUUmjJK2IiE2FZQZ0CLWNqmrlHLoi4hFJjxSUC9A1qG1UEVeKAkAiaOgAkAgaOgAkgoYOAImgoQNAImjoAJAIGjoAJIKGDgCJoKEDQCJo6ACQCBo6ACSChg4AiaChA0AiaOgAkAgaOgAkgoYOAImgoQNAImjoAJAIGjoAJKKle4ra3iZpr6QBSQcjoreIpFLn0dkf+6gPHd/Se7705zNy4wPjD2ViJ83amTt2/NXOxH5xy5jcsRt6v5+J7Rp4J3fsmfcvzsQ++mdP547tFtR293t0x3N1j73ohDktvb6R9+2klhp6zWciYlcB7wN0G2oblcIpFwBIRKsNPST9u+1nbS8sIiGgS1DbqJxWT7mcExE7bE+RtMb2ixHxxOABtb8MCyVpnMa3uDmgbahtVE5LR+gRsaP2uFPSQ5Lm5oxZFhG9EdHbo7GtbA5oG2obVdT0Ebrt4yS9LyL21p5fKOmbhWXWBUadOjsTi7E9uWN3fPqDmdi7Z+Wv+pj8gWz8yU9mV42U5d9+NTE3/q1/nJ+JrTv9ntyxrx54NxNb2n9B7tgTnowGsuu8kVDbrSpihUg7VS3fZrVyymWqpIdsH3mfeyLiR4VkBXQWtY1KarqhR8RWSZ8sMBegK1DbqCqWLQJAImjoAJCIIq4UrbyB8347N37LytszsZN78i+F71YHYiAT++vbvpQ7dvQ72cnLs+9flDt24usHM7Gxu7ITpZI0fv26Y2SITkh1krDbLsVvN47QASARNHQASAQNHQASQUMHgETQ0AEgEaxykTT2pR258Wffm56JndzTX3Y6/2dx31m58a1vZ2+GsXLWD3PHvnUou3Jl6nf/s7XEhlCtC/yB9HCEDgCJoKEDQCJo6ACQCBo6ACSCSVFJB/t+kRu/7VuXZ2I3z8//jPNRz0/IxH5y9W1153DTrt/KxF753fy74Ay82ZeJ/eHZV+eO3faNbGymflJ3XkhT3iXyQ30cQCNjW9l+o1L9+IJWcIQOAImgoQNAImjoAJAIGjoAJGLYhm57he2dtjcOik22vcb2ltrjpHLTBIpHbSM1jjj2Bdu250l6W9JdEXFaLfZ3knZHxFLbSyRNiojrhtvY+z05zvT5BaTdOaOO//Xc+MAbuzOxV+/JrlyRpE3zVmRic//265nYlNvLuUQ/VetirfbEbtc7ntpuXiMrTEb6TSeKUG9tD3uEHhFPSDq6W10iaVXt+SpJlzacIdBh1DZS0+w59KkR0SdJtccpxaUEdBS1jcoq/cIi2wslLZSkccq/UAaoImob3abZI/R+29Mkqfa4c6iBEbEsInojordHY5vcHNA21DYqq9kj9NWSrpS0tPb4cGEZdbmBXW/UPfbAnjF1j/3EF36aif3yjlH5gw8N1P2+aNiIre2y5E2gMlFajnqWLd4r6SlJH7O93fZXdLjYL7C9RdIFta+BSqG2kZphj9AjYsEQ3xo5a7SQJGobqeFKUQBIBA0dABJBQweARHCDixKdet3LufEvn549Rfu9k9ZmYp++/Gu5r5/4/adbSwxo0VCrVLjpRGdxhA4AiaChA0AiaOgAkAgaOgAkgknREg28+VZu/I2rTs3EXlv9bia25Ka7cl//l39wWSYW//2B3LHTb34qGxzmM/CBZuVNluZNlPJ56uXgCB0AEkFDB4BE0NABIBE0dABIxLA3iS7SSLuRbiN2/9HZmdjdN3w7d+zM0ePqft9P3LUoE5u9vC937MGt2+p+327U6E2ii0RtN6aIK0pH0mRpYTeJBgBUAw0dABJBQweARNDQASAR9dxTdIXtnbY3DordaPt128/V/lxcbppA8ahtpGbYVS6250l6W9JdEXFaLXajpLcjIn8ZxhBYCdCYOCd/Fv/9S7dnYvf+5qN1v+8pj/1xbvxjf5P9qIKBLVvrft9Oa3SVC7Xdfcr6PPWqr4gpbJVLRDwhaXchWQFdhNpGalo5h77I9vO1/7ZOKiwjoPOobVRSsw39DkmzJM2R1CfpO0MNtL3Q9nrb6w9oX5ObA9qG2kZlNdXQI6I/IgYi4pCk5ZLmHmPssojojYjeHo1tNk+gLahtVFlTn4due1pEHLl+/DJJG481Hs3xf+RPEP3q96dkYr9zxddzx6677tZM7MXP/HPu2C/MuDATe+vcY2WYHmq7sxqZvGxkAjVvbNUnSvMM29Bt3yvpPEnH294u6QZJ59meIykkbZP01RJzBEpBbSM1wzb0iFiQE76zhFyAtqK2kRquFAWARNDQASARNHQASERTq1zQWQP9OzOxqd/NxiTpvb84mImN95jcsctn/Gsm9rnLrs0dO/6hdcdKEUAHcIQOAImgoQNAImjoAJAIGjoAJIJJ0S526Nz8S5N/dvm4TOy0Odtyxw41AZrntt1nZF//8Pq6Xw+0qqzPQx8pOEIHgETQ0AEgETR0AEgEDR0AEkFDB4BEsMqlA9x7Wib28jeyq1GWn7Mq9/Xzxu1vafv74kBu/OndM7PBQ33ZGNAAVq60D0foAJAIGjoAJIKGDgCJGLah255u+zHbm21vsn1NLT7Z9hrbW2qPk8pPFygOtY3U1DMpelDS4ojYYHuipGdtr5H0JUlrI2Kp7SWSlki6rrxUu9vomSdlYj/78gm5Y2+84r5M7Pcm7Co8J0m6vr83E3v81rNyx05a9VQpOXQxartgnZ4AveiE/I/LGCmGPUKPiL6I2FB7vlfSZkknSrpE0pFlGKskXVpWkkAZqG2kpqFz6LZnSDpD0jpJUyOiTzr8F0PSlKKTA9qF2kYK6m7otidIekDStRGxp4HXLbS93vb6A9rXTI5AqahtpKKuhm67R4cL/u6IeLAW7rc9rfb9aZJyb2oZEcsiojciens0toicgcJQ20hJPatcLOlOSZsj4pZB31ot6cra8yslPVx8ekB5qG2kpp5VLudI+qKkF2wfmcK+XtJSST+w/RVJr0m6vJwUO2f0jI9kYm99alru2Cu++aNM7E8++GDOyNYt7suuUnnqn7KrWSRp8sr/ysQmHRpxq1mGMmJruxGsXKmOYRt6RPxYkof49vnFpgO0D7WN1HClKAAkgoYOAImgoQNAIkbc56GPnvYbmdjuFcfljr1q5uOZ2IKJ/YXnJEmLXj83E9twR/5k0PE/3JiJTd7LRCeyOj2hORQmOsvBEToAJIKGDgCJoKEDQCJo6ACQCBo6ACQiiVUu+y/KXva+/0935469/qOPZGIX/to7heckSf0D7+bG561enImd8lcvZmKT38xfuXKotbRQcd26cmUorGhpH47QASARNHQASAQNHQASQUMHgEQkMSm67dLsv0svn35/y+97+5uzMrFbH78wd6wHsp/CespNr+aOnd2/LhMbaDA3jAzdOgHKRGd34ggdABJBQweARNDQASAR9dwkerrtx2xvtr3J9jW1+I22X7f9XO3PxeWnCxSH2kZq6pkUPShpcURssD1R0rO219S+9/cR8e3y0gNKRW0jKfXcJLpPUl/t+V7bmyWdWHZijTj5quyd7T931afK2Zay2xoKK1e6WxVqm9UkaERD59Btz5B0hqQj6+4W2X7e9grbkwrODWgbahspqLuh254g6QFJ10bEHkl3SJolaY4OH+V8Z4jXLbS93vb6A9pXQMpAsahtpKKuhm67R4cL/u6IeFCSIqI/IgYi4pCk5ZLm5r02IpZFRG9E9PZobFF5A4WgtpGSela5WNKdkjZHxC2D4tMGDbtMUvbOxUAXo7aRmnpWuZwj6YuSXrB95Drk6yUtsD1HUkjaJumrpWQIlIfaRlLqWeXyY0nZDyqRsneKACqE2kZquFIUABJBQweARNDQASARNHQASAQNHQASQUMHgETQ0AEgETR0AEgEDR0AEuGIaN/G7F9K+p/al8dL2tW2jbcP+9U5J0XEhzqx4UG1XYWfU7NS3bcq7Fddtd3Whv7/Nmyvj4jejmy8ROzXyJbyzynVfUtpvzjlAgCJoKEDQCI62dCXdXDbZWK/RraUf06p7lsy+9Wxc+gAgGJxygUAEtH2hm57vu2XbL9ie0m7t1+k2h3hd9reOCg22fYa21tqj5W7Y7zt6bYfs73Z9ibb19Tild+3MqVS29R19fbtiLY2dNujJN0u6bOSPq7Dt/r6eDtzKNhKSfOPii2RtDYiZktaW/u6ag5KWhwRp0o6S9LXar+nFPatFInV9kpR15XU7iP0uZJeiYitEbFf0n2SLmlzDoWJiCck7T4qfImkVbXnqyRd2takChARfRGxofZ8r6TNkk5UAvtWomRqm7qu3r4d0e6GfqKknw/6enstlpKpEdEnHS4gSVM6nE9LbM+QdIakdUps3wqWem0n9btPta7b3dDzbsjLMpsuZXuCpAckXRsRezqdT5ejtisi5bpud0PfLmn6oK8/LGlHm3MoW7/taZJUe9zZ4XyaYrtHh4v+7oh4sBZOYt9KknptJ/G7T72u293Qn5E02/ZM22MkfV7S6jbnULbVkq6sPb9S0sMdzKUpti3pTkmbI+KWQd+q/L6VKPXarvzvfiTUddsvLLJ9saR/kDRK0oqIuLmtCRTI9r2SztPhT2vrl3SDpH+R9ANJH5H0mqTLI+LoCaauZvtcSU9KekHSoVr4eh0+31jpfStTKrVNXVdv347gSlEASARXigJAImjoAJAIGjoAJIKGDgCJoKEDQCJo6ACQCBo6ACSChg4Aifhfes3qCK+UfH8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, test = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "# Quick check on the sizes of the datasets\n",
    "print(\"Training samples: \", len(train[0]))\n",
    "print(\"Training set shape: \", train[0].shape)\n",
    "print(\"Test cases: \", len(test[0]))\n",
    "\n",
    "# Checking the size of each sample\n",
    "print(\"Training shape: \", train[0][0].shape)\n",
    "\n",
    "# print(train[0][0]) -- examining the values; 0-255\n",
    "\n",
    "# Checking out a sample\n",
    "image = train[0][0]\n",
    "plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "plt.show()\n",
    "\n",
    "# Copying the sample, thresholding activations at >0.5 == 1, <0.5 == 0\n",
    "example = train[0][0]\n",
    "example = example / 255.0\n",
    "\n",
    "for i, x in enumerate(example):\n",
    "    for j, y in enumerate(x):\n",
    "        if y < 0.5:\n",
    "            example[i][j] = 0\n",
    "        else:\n",
    "            example[i][j] = 1\n",
    "\n",
    "f, axarr = plt.subplots(1, 2)\n",
    "axarr[0].imshow(image)\n",
    "axarr[1].imshow(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM():\n",
    "    def __init__(self, v_units=784, h_units=200, k_steps=35):\n",
    "        self.num_visible = v_units # visible units\n",
    "        self.num_hidden = h_units # hidden units\n",
    "        self.k_steps = k_steps # k-steps for contrastive divergence\n",
    "        \n",
    "        self.alpha = tf.Variable(0.1) # learning rate\n",
    "        \n",
    "        # RBM architecture will be two layers only - visible and hidden, none else; not a DBM\n",
    "        self.weights = tf.Variable(tf.truncated_normal(shape=[self.num_visible, self.num_hidden], stddev=0.1), name='weights')\n",
    "        self.v_biases = tf.Variable(tf.constant(1.0, shape=[self.num_visible]), name='visible_biases')\n",
    "        self.h_biases = tf.Variable(tf.constant(1.0, shape=[self.num_hidden]), name='hidden_biases')\n",
    "        \n",
    "    def vhActivation(self, visible):\n",
    "        # We use the result of sigmoid activation as the probability of neuron firing\n",
    "        input = tf.matmul(visible, self.weights) + self.h_biases\n",
    "        return tf.nn.sigmoid(input)\n",
    "    \n",
    "    def hvActivation(self, hidden):\n",
    "        # Same case, in reverse\n",
    "        input = tf.matmul(hidden, tf.transpose(self.weights)) + self.v_biases\n",
    "        return tf.nn.sigmoid(input)\n",
    "    \n",
    "    # Two following functions are Gibbs sampling steps\n",
    "    # To simulate the firing of stochastic binary neurons, we make use of tf.random_uniform\n",
    "    # which generates random vals between [0, 1) for floats. As they are random,\n",
    "    # we don't know which are larger/smaller than the sigmoid activations.\n",
    "    # So we subtract them from the sigmoid activations and then use ReLU to decide which neurons have fired 'stochastically'\n",
    "    # and which haven't. tf.sign raises the values that would survive to 1, and drops the losing neurons to -1 to be culled by ReLU\n",
    "    def sample_h(self, v_sample):\n",
    "        h = self.vhActivation(v_sample)\n",
    "        h_sample = tf.nn.relu(tf.sign(h - tf.random_uniform(tf.shape(h))))\n",
    "        return h_sample\n",
    "    \n",
    "    def sample_v(self, h_sample):\n",
    "        v = self.hvActivation(h_sample)\n",
    "        v_sample = tf.nn.relu(tf.sign(v - tf.random_uniform(tf.shape(v))))\n",
    "        return v_sample\n",
    "    \n",
    "    # CDk learning algorithm\n",
    "    def CD_k(self, v):\n",
    "        # sample with k steps of Gibbs\n",
    "        v_sample = v\n",
    "        h_sample = self.sample_h(v_sample) # generating the first step in the Markov chain from time t=0\n",
    "        \n",
    "        for step in range(self.k_steps): # subsequent time steps in the Markov chain progress now for k steps\n",
    "            v_sample = self.sample_v(h_sample)\n",
    "            h_sample = self.sample_h(v_sample)\n",
    "        \n",
    "        # The learning rule is ΔW = ε(<vh>0 - <vh>k)\n",
    "        # in <vh>0, v is the visible vector at the beginning of the Markov particle, h is sample generated given that v.\n",
    "        # in <vh>k, the last sampling taken from the chain, v and h are both final samples generated from the chain\n",
    "        h = self.vhActivation(v)\n",
    "        positive_statistic = tf.matmul(tf.transpose(v), h) # wish to increase probability of the visible vector\n",
    "        negative_statistic = tf.matmul(tf.transpose(v_sample), h_sample) # decrease probabilities of competing vectors\n",
    "        w_grad = (positive_statistic - negative_statistic) / tf.to_float(tf.shape(v)[0])\n",
    "        \n",
    "        # in keeping with the guides I'm following, I'll perform these next two steps.\n",
    "        # They look to be gradients for the biases\n",
    "        hb_grad = tf.reduce_mean(h - h_sample, 0)\n",
    "        vb_grad = tf.reduce_mean(v - v_sample, 0)\n",
    "        \n",
    "        return w_grad, hb_grad, vb_grad\n",
    "    \n",
    "    def learning_step(self, v):\n",
    "        w_grad, hb_grad, vb_grad = self.CD_k(v)\n",
    "        \n",
    "        w = tf.assign(self.weights, self.alpha * w_grad)\n",
    "        hb = tf.assign(self.h_biases, self.alpha * hb_grad)\n",
    "        vb = tf.assign(self.v_biases, self.alpha * vb_grad)\n",
    "        return [w, vb, hb]\n",
    "    \n",
    "    # function to get samples of reconstructed images from the model\n",
    "    # run for a number of steps to approach the stationary distribution of the model\n",
    "    # then return a reconstruction to display\n",
    "    def imageSample(self, v, steps=5000):\n",
    "        v_sample = v\n",
    "        # Run chain for 'steps' iterations before taking a sample - default is 5000 steps\n",
    "        for step in range(steps):\n",
    "            v_sample = self.sample_v(self.sample_h((v_sample)))\n",
    "        return v_sample\n",
    "    \n",
    "    # Functions for calculating likelihood now follow\n",
    "    # Our objective function is to maximize the likelihood of visible vectors from the dataset\n",
    "    # while reducing the likelihood of competitor vectors\n",
    "    # to track this, we try to quantify the log probabilities\n",
    "    # but because the amount of join configurations of (v, h) vary exponentially with the number of units,\n",
    "    # we compute approximations instead; pseudo likelihood.\n",
    "    def free_energy(self, v):\n",
    "        # (1 x num_visible) * (num_visible x 1) -> real value output\n",
    "        print(v.get_shape())\n",
    "        print(self.v_biases.get_shape())\n",
    "        visible_activations = tf.matmul(v, tf.reshape(self.v_biases, [tf.shape(self.v_biases)[0], 1]))\n",
    "        # visible activations took care of energy contributions from the visible units and their biases\n",
    "        # activations within the hidden layer, including visible-hidden contributions, are exponentiated\n",
    "        # and marginalized in the logarithmic domain\n",
    "        activations = tf.reduce_sum(tf.log(1 + tf.exp(self.h_biases + tf.matmul(v, self.weights))), axis=1)\n",
    "        return -(visible_activations - activations)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    def pseudo_log_likelihood(self, v):\n",
    "        vec = tf.round(v)\n",
    "        vec_fe = self.free_energy(vec)\n",
    "        split0, split1, split2 = tf.split(vec, [self.i, 1, tf.shape(vec)[1] - self.i - 1], 1)\n",
    "        veci = tf.concat([split0, 1 - split1, split2], 1)\n",
    "        self.i = (self.i + 1) % self.num_visible\n",
    "        veci_fe = self.free_energy(veci)\n",
    "        return tf.reduce_mean(self.num_visible * tf.log(tf.nn.sigmoid(veci_fe - vec_fe)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-52761b457bdb>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-52761b457bdb>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    def next_batch_indices()\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# quick helper function to pull out the relevant training vectors\n",
    "# from the training set.\n",
    "def next_batch(index, batch_sz, len_dataset):\n",
    "    start = (index * batch_sz) % len_dataset # 0-31, 32-63, 64-95\n",
    "    end = start + (batch_sz - 1)\n",
    "    if (end >= len_dataset):\n",
    "        end = len_dataset - 1\n",
    "    return start, end\n",
    "    \n",
    "\n",
    "def trainRBM(training_data, test_data, epochs, batch_size=32):\n",
    "    \n",
    "    data = np.float32(np.reshape(training_data, [60000, 784]))\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    \n",
    "    rbm = RBM()\n",
    "    rbm.alpha = 0.1\n",
    "    \n",
    "    step = rbm.learning_step(x)\n",
    "    sampler = rbm.imageSample(x)\n",
    "    pl = rbm.pseudo_log_likelihood(x)\n",
    "    \n",
    "    num_batches = int(len(training_data) / batch_size) # Changing to use batch_sizes and avoid the ResourceExhaustedError.\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    print(\"First checkpoint passed\")\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        mean_cost = [] # averaging cost over 500 epochs\n",
    "        print(\"Onto the epochs!\")\n",
    "        for i in range(epochs * num_batches): # Change made again here. Similar changes need all throughout to settle this.\n",
    "            start, end = next_batch(i, batch_size, len(training_data))\n",
    "            cost = sess.run(pl, feed_dict={x: data[start:end]} )\n",
    "            mean_cost.append(cost)\n",
    "\n",
    "            # draw a sample every 500 epochs\n",
    "            if i % 500 == 0:\n",
    "                sample = sess.run(sampler, feed_dict = {x: data})\n",
    "                sample = sample[random.randrange(59999)].reshape([28, 28])\n",
    "                plt.imshow(sample, cmap=plt.get_cmap('gray_r'))\n",
    "                print('Epoch ', i+1, ', Cost: ', np.mean(mean_cost))\n",
    "                mean_cost = []\n",
    "\n",
    "        print('Test data')\n",
    "        testCase = random.randrange(9999)\n",
    "        sample = sess.run(sampler, feed_dict = {x: test_data[testCase]})\n",
    "        sample = sample.reshape([28, 28])\n",
    "        plt.title(\"Label: %d\" % test[1][testCase])\n",
    "        plt.imshow(sample)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 784)\n",
      "(784,)\n",
      "(?, ?)\n",
      "(784,)\n",
      "First checkpoint passed\n",
      "Onto the epochs!\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[60000,60000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: sub_70538 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](MatMul_70532, Sum_6)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_16/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_75_Mean_16\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'sub_70538', defined at:\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_64\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_64\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel\\kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_64\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_64\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_64\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\IPython\\core\\interactiveshell.py\", line 2907, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-30-e94a130440f2>\", line 1, in <module>\n    trainRBM(train[0], test[0], 3000)\n  File \"<ipython-input-29-a6392fcf0595>\", line 14, in trainRBM\n    pl = rbm.pseudo_log_likelihood(x)\n  File \"<ipython-input-16-08c50976cbe6>\", line 104, in pseudo_log_likelihood\n    vec_fe = self.free_energy(vec)\n  File \"<ipython-input-16-08c50976cbe6>\", line 98, in free_energy\n    return -(visible_activations - activations)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 847, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 8582, in sub\n    \"Sub\", x=x, y=y, name=name)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[60000,60000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: sub_70538 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](MatMul_70532, Sum_6)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_16/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_75_Mean_16\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[60000,60000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: sub_70538 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](MatMul_70532, Sum_6)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_16/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_75_Mean_16\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-e94a130440f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainRBM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-a6392fcf0595>\u001b[0m in \u001b[0;36mtrainRBM\u001b[1;34m(training_data, test_data, epochs)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Onto the epochs!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mmean_cost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[60000,60000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: sub_70538 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](MatMul_70532, Sum_6)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_16/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_75_Mean_16\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'sub_70538', defined at:\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_64\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_64\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel\\kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_64\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_64\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_64\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\IPython\\core\\interactiveshell.py\", line 2907, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-30-e94a130440f2>\", line 1, in <module>\n    trainRBM(train[0], test[0], 3000)\n  File \"<ipython-input-29-a6392fcf0595>\", line 14, in trainRBM\n    pl = rbm.pseudo_log_likelihood(x)\n  File \"<ipython-input-16-08c50976cbe6>\", line 104, in pseudo_log_likelihood\n    vec_fe = self.free_energy(vec)\n  File \"<ipython-input-16-08c50976cbe6>\", line 98, in free_energy\n    return -(visible_activations - activations)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 847, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 8582, in sub\n    \"Sub\", x=x, y=y, name=name)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\anant\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[60000,60000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: sub_70538 = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](MatMul_70532, Sum_6)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_16/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_75_Mean_16\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "trainRBM(train[0], test[0], 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
