{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow: 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"Tensorflow: {}\".format(tf.VERSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll load the dataset and inspect it a little - I have two approaches in mind, both of which involve scaling pixel intensities down to [0, 1]:\n",
    "1) Threshold pixel classes at 0.5 - <0.5 is white, >0.5 is black\n",
    "2) Treat the pixel intensities as the likelihood of activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:  60000\n",
      "Training set shape:  (60000, 28, 28)\n",
      "Test cases:  10000\n",
      "Training shape:  (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d1c16cc518>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, test = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "# Quick check on the sizes of the datasets\n",
    "print(\"Training samples: \", len(train[0]))\n",
    "print(\"Training set shape: \", train[0].shape)\n",
    "print(\"Test cases: \", len(test[0]))\n",
    "\n",
    "# Checking the size of each sample\n",
    "print(\"Training shape: \", train[0][0].shape)\n",
    "\n",
    "# print(train[0][0]) -- examining the values; 0-255\n",
    "\n",
    "# Checking out a sample\n",
    "image = train[0][0]\n",
    "plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "plt.show()\n",
    "\n",
    "# Copying the sample, thresholding activations at >0.5 == 1, <0.5 == 0\n",
    "example = train[0][0]\n",
    "example = example / 255.0\n",
    "\n",
    "for i, x in enumerate(example):\n",
    "    for j, y in enumerate(x):\n",
    "        if y < 0.5:\n",
    "            example[i][j] = 0\n",
    "        else:\n",
    "            example[i][j] = 1\n",
    "\n",
    "f, axarr = plt.subplots(1, 2)\n",
    "axarr[0].imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "axarr[1].imshow(example, cmap=plt.get_cmap('gray_r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM():\n",
    "    def __init__(self, v_units=784, h_units=200, k_steps=35):\n",
    "        self.num_visible = v_units # visible units\n",
    "        self.num_hidden = h_units # hidden units\n",
    "        self.k_steps = k_steps # k-steps for contrastive divergence\n",
    "        \n",
    "        self.alpha = tf.Variable(0.1) # learning rate\n",
    "        \n",
    "        # RBM architecture will be two layers only - visible and hidden, none else; not a DBM\n",
    "        self.weights = tf.Variable(tf.truncated_normal(shape=[self.num_visible, self.num_hidden], stddev=0.1), name='weights')\n",
    "        self.v_biases = tf.Variable(tf.constant(1.0, shape=[self.num_visible]), name='visible_biases')\n",
    "        self.h_biases = tf.Variable(tf.constant(1.0, shape=[self.num_hidden]), name='hidden_biases')\n",
    "        \n",
    "    def vhActivation(self, visible):\n",
    "        # We use the result of sigmoid activation as the probability of neuron firing\n",
    "        input = tf.matmul(visible, self.weights) + self.h_biases\n",
    "        return tf.nn.sigmoid(input)\n",
    "    \n",
    "    def hvActivation(self, hidden):\n",
    "        # Same case, in reverse\n",
    "        input = tf.matmul(hidden, tf.transpose(self.weights)) + self.v_biases\n",
    "        return tf.nn.sigmoid(input)\n",
    "    \n",
    "    # Two following functions are Gibbs sampling steps\n",
    "    # To simulate the firing of stochastic binary neurons, we make use of tf.random_uniform\n",
    "    # which generates random vals between [0, 1) for floats. As they are random,\n",
    "    # we don't know which are larger/smaller than the sigmoid activations.\n",
    "    # So we subtract them from the sigmoid activations and then use ReLU to decide which neurons have fired 'stochastically'\n",
    "    # and which haven't. tf.sign raises the values that would survive to 1, and drops the losing neurons to -1 to be culled by ReLU\n",
    "    def sample_h(self, v_sample):\n",
    "        h = self.vhActivation(v_sample)\n",
    "        h_sample = tf.nn.relu(tf.sign(h - tf.random_uniform(tf.shape(h))))\n",
    "        return h_sample\n",
    "    \n",
    "    def sample_v(self, h_sample):\n",
    "        v = self.hvActivation(h_sample)\n",
    "        v_sample = tf.nn.relu(tf.sign(v - tf.random_uniform(tf.shape(v))))\n",
    "        return v_sample\n",
    "    \n",
    "    # CDk learning algorithm\n",
    "    def CD_k(self, v):\n",
    "        # sample with k steps of Gibbs\n",
    "        v_sample = v\n",
    "        h_sample = self.sample_h(v_sample) # generating the first step in the Markov chain from time t=0\n",
    "        \n",
    "        for step in range(self.k_steps): # subsequent time steps in the Markov chain progress now for k steps\n",
    "            v_sample = self.sample_v(h_sample)\n",
    "            h_sample = self.sample_h(v_sample)\n",
    "        \n",
    "        # The learning rule is ΔW = ε(<vh>0 - <vh>k)\n",
    "        # in <vh>0, v is the visible vector at the beginning of the Markov particle, h is sample generated given that v.\n",
    "        # in <vh>k, the last sampling taken from the chain, v and h are both final samples generated from the chain\n",
    "        h = self.vhActivation(v)\n",
    "        positive_statistic = tf.matmul(tf.transpose(v), h) # wish to increase probability of the visible vector\n",
    "        negative_statistic = tf.matmul(tf.transpose(v_sample), h_sample) # decrease probabilities of competing vectors\n",
    "        w_grad = (positive_statistic - negative_statistic) / tf.to_float(tf.shape(v)[0])\n",
    "        \n",
    "        # in keeping with the guides I'm following, I'll perform these next two steps.\n",
    "        # They look to be gradients for the biases\n",
    "        hb_grad = tf.reduce_mean(h - h_sample, 0)\n",
    "        vb_grad = tf.reduce_mean(v - v_sample, 0)\n",
    "        \n",
    "        return w_grad, hb_grad, vb_grad\n",
    "    \n",
    "    def learning_step(self, v):\n",
    "        w_grad, hb_grad, vb_grad = self.CD_k(v)\n",
    "        \n",
    "        w = tf.assign(self.weights, self.alpha * w_grad)\n",
    "        hb = tf.assign(self.h_biases, self.alpha * hb_grad)\n",
    "        vb = tf.assign(self.v_biases, self.alpha * vb_grad)\n",
    "        return [w, vb, hb]\n",
    "    \n",
    "    # function to get samples of reconstructed images from the model\n",
    "    # run for a number of steps to approach the stationary distribution of the model\n",
    "    # then return a reconstruction to display\n",
    "    def imageSample(self, v, steps=5000):\n",
    "        v_sample = v\n",
    "        # Run chain for 'steps' iterations before taking a sample - default is 5000 steps\n",
    "        for step in range(steps):\n",
    "            v_sample = self.sample_v(self.sample_h((v_sample)))\n",
    "        return v_sample\n",
    "    \n",
    "    # Functions for calculating likelihood now follow\n",
    "    # Our objective function is to maximize the likelihood of visible vectors from the dataset\n",
    "    # while reducing the likelihood of competitor vectors\n",
    "    # to track this, we try to quantify the log probabilities\n",
    "    # but because the amount of join configurations of (v, h) vary exponentially with the number of units,\n",
    "    # we compute approximations instead; pseudo likelihood.\n",
    "    def free_energy(self, v):\n",
    "        # (1 x num_visible) * (num_visible x 1) -> real value output\n",
    "        print(v.get_shape())\n",
    "        print(self.v_biases.get_shape())\n",
    "        visible_activations = tf.matmul(v, tf.reshape(self.v_biases, [tf.shape(self.v_biases)[0], 1]))\n",
    "        # visible activations took care of energy contributions from the visible units and their biases\n",
    "        # activations within the hidden layer, including visible-hidden contributions, are exponentiated\n",
    "        # and marginalized in the logarithmic domain\n",
    "        activations = tf.reduce_sum(tf.log(1 + tf.exp(self.h_biases + tf.matmul(v, self.weights))), axis=1)\n",
    "        return -(visible_activations - activations)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    def pseudo_log_likelihood(self, v):\n",
    "        vec = tf.round(v)\n",
    "        vec_fe = self.free_energy(vec)\n",
    "        split0, split1, split2 = tf.split(vec, [self.i, 1, tf.shape(vec)[1] - self.i - 1], 1)\n",
    "        veci = tf.concat([split0, 1 - split1, split2], 1)\n",
    "        self.i = (self.i + 1) % self.num_visible\n",
    "        veci_fe = self.free_energy(veci)\n",
    "        print(veci_fe)\n",
    "        print(vec_fe)\n",
    "        return tf.reduce_mean(self.num_visible * tf.log(tf.nn.sigmoid(veci_fe - vec_fe)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# quick helper function to pull out the relevant training vectors\n",
    "# from the training set.\n",
    "def next_batch(index, batch_sz, len_dataset):\n",
    "    start = (index * batch_sz) % len_dataset # 0-31, 32-63, 64-95\n",
    "    end = start + (batch_sz)\n",
    "    if (end >= len_dataset):\n",
    "        end = len_dataset\n",
    "    return start, end\n",
    "    \n",
    "\n",
    "def trainRBM(training_data, test_data, epochs, batch_size=32):\n",
    "    \n",
    "    data = np.float32(np.reshape(training_data, [60000, 784]))\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    \n",
    "    rbm = RBM()\n",
    "    rbm.alpha = 0.1\n",
    "    \n",
    "    step = rbm.learning_step(x)\n",
    "    sampler = rbm.imageSample(x)\n",
    "    pl = rbm.pseudo_log_likelihood(x)\n",
    "    \n",
    "    num_batches = int(len(training_data) / batch_size) # Changing to use batch_sizes and avoid the ResourceExhaustedError.\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    print(\"First checkpoint passed\")\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        mean_cost = [] # averaging cost over 500 epochs\n",
    "        print(\"Onto the epochs!\")\n",
    "        for i in range(epochs * num_batches): # Change made again here. Similar changes need all throughout to settle this.\n",
    "            start, end = next_batch(i, batch_size, len(training_data))\n",
    "            sess.run(step, feed_dict={x:data[start:end]})\n",
    "            cost = sess.run(pl, feed_dict={x: data[start:end]} )\n",
    "            mean_cost.append(cost)\n",
    "\n",
    "            # draw a sample every 500 epochs\n",
    "            if i % 500 == 0:\n",
    "                # samples being drawn from within the same batch, because I'm just eager to see something.\n",
    "                sample = sess.run(sampler, feed_dict = {x: data[start:end]})\n",
    "                sample = sample[random.randrange(batch_size)].reshape([28, 28])\n",
    "                plt.imshow(sample, cmap=plt.get_cmap('gray_r'))\n",
    "                print('Epoch ', i, ', Cost: ', np.mean(mean_cost))\n",
    "                mean_cost = []\n",
    "\n",
    "        print('Test data')\n",
    "        testCase = random.randrange(len(test_data))\n",
    "        vis_vector = np.reshape(test_data[testCase], [1, 784])\n",
    "        sample = sess.run(sampler, feed_dict = {x: vis_vector})\n",
    "        sample = sample.reshape([28, 28])\n",
    "        plt.title(\"Label: %d\" % test[1][testCase])\n",
    "        plt.imshow(sample, cmap=plt.get_cmap('gray_r'))\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 784)\n",
      "(784,)\n",
      "(?, ?)\n",
      "(784,)\n",
      "Tensor(\"Neg_9:0\", shape=(?, ?), dtype=float32)\n",
      "Tensor(\"Neg_8:0\", shape=(?, ?), dtype=float32)\n",
      "First checkpoint passed\n",
      "Onto the epochs!\n",
      "Epoch  0 , Cost:  nan\n",
      "Epoch  500 , Cost:  nan\n",
      "Epoch  1000 , Cost:  nan\n",
      "Epoch  1500 , Cost:  nan\n",
      "Epoch  2000 , Cost:  nan\n",
      "Epoch  2500 , Cost:  nan\n",
      "Epoch  3000 , Cost:  nan\n",
      "Epoch  3500 , Cost:  nan\n",
      "Epoch  4000 , Cost:  nan\n",
      "Epoch  4500 , Cost:  nan\n",
      "Epoch  5000 , Cost:  nan\n",
      "Epoch  5500 , Cost:  nan\n",
      "Epoch  6000 , Cost:  nan\n",
      "Epoch  6500 , Cost:  nan\n",
      "Epoch  7000 , Cost:  nan\n",
      "Epoch  7500 , Cost:  nan\n",
      "Epoch  8000 , Cost:  nan\n",
      "Epoch  8500 , Cost:  nan\n",
      "Epoch  9000 , Cost:  nan\n",
      "Epoch  9500 , Cost:  nan\n",
      "Epoch  10000 , Cost:  nan\n",
      "Epoch  10500 , Cost:  nan\n",
      "Epoch  11000 , Cost:  nan\n",
      "Epoch  11500 , Cost:  nan\n",
      "Epoch  12000 , Cost:  nan\n",
      "Epoch  12500 , Cost:  nan\n",
      "Epoch  13000 , Cost:  nan\n",
      "Epoch  13500 , Cost:  nan\n",
      "Epoch  14000 , Cost:  nan\n",
      "Epoch  14500 , Cost:  nan\n",
      "Epoch  15000 , Cost:  nan\n",
      "Epoch  15500 , Cost:  nan\n",
      "Epoch  16000 , Cost:  nan\n",
      "Epoch  16500 , Cost:  nan\n",
      "Epoch  17000 , Cost:  nan\n",
      "Epoch  17500 , Cost:  nan\n",
      "Epoch  18000 , Cost:  nan\n",
      "Epoch  18500 , Cost:  nan\n",
      "Epoch  19000 , Cost:  nan\n",
      "Epoch  19500 , Cost:  nan\n",
      "Epoch  20000 , Cost:  nan\n",
      "Epoch  20500 , Cost:  nan\n",
      "Epoch  21000 , Cost:  nan\n",
      "Epoch  21500 , Cost:  nan\n",
      "Epoch  22000 , Cost:  nan\n",
      "Epoch  22500 , Cost:  nan\n",
      "Epoch  23000 , Cost:  nan\n",
      "Epoch  23500 , Cost:  nan\n",
      "Epoch  24000 , Cost:  nan\n",
      "Epoch  24500 , Cost:  nan\n",
      "Epoch  25000 , Cost:  nan\n",
      "Epoch  25500 , Cost:  nan\n",
      "Epoch  26000 , Cost:  nan\n",
      "Epoch  26500 , Cost:  nan\n",
      "Epoch  27000 , Cost:  nan\n",
      "Epoch  27500 , Cost:  nan\n",
      "Epoch  28000 , Cost:  nan\n",
      "Epoch  28500 , Cost:  nan\n",
      "Epoch  29000 , Cost:  nan\n",
      "Epoch  29500 , Cost:  nan\n",
      "Epoch  30000 , Cost:  nan\n",
      "Epoch  30500 , Cost:  nan\n",
      "Epoch  31000 , Cost:  nan\n",
      "Epoch  31500 , Cost:  nan\n",
      "Epoch  32000 , Cost:  nan\n",
      "Epoch  32500 , Cost:  nan\n",
      "Epoch  33000 , Cost:  nan\n",
      "Epoch  33500 , Cost:  nan\n",
      "Epoch  34000 , Cost:  nan\n",
      "Epoch  34500 , Cost:  nan\n",
      "Epoch  35000 , Cost:  nan\n",
      "Epoch  35500 , Cost:  nan\n",
      "Epoch  36000 , Cost:  nan\n",
      "Epoch  36500 , Cost:  nan\n",
      "Epoch  37000 , Cost:  nan\n",
      "Epoch  37500 , Cost:  nan\n",
      "Epoch  38000 , Cost:  nan\n",
      "Epoch  38500 , Cost:  nan\n",
      "Epoch  39000 , Cost:  nan\n",
      "Epoch  39500 , Cost:  nan\n",
      "Epoch  40000 , Cost:  nan\n",
      "Epoch  40500 , Cost:  nan\n",
      "Epoch  41000 , Cost:  nan\n",
      "Epoch  41500 , Cost:  nan\n",
      "Epoch  42000 , Cost:  nan\n",
      "Epoch  42500 , Cost:  nan\n",
      "Epoch  43000 , Cost:  nan\n",
      "Epoch  43500 , Cost:  nan\n",
      "Epoch  44000 , Cost:  nan\n",
      "Epoch  44500 , Cost:  nan\n",
      "Epoch  45000 , Cost:  nan\n",
      "Epoch  45500 , Cost:  nan\n",
      "Epoch  46000 , Cost:  nan\n",
      "Epoch  46500 , Cost:  nan\n",
      "Epoch  47000 , Cost:  nan\n",
      "Epoch  47500 , Cost:  nan\n",
      "Epoch  48000 , Cost:  nan\n",
      "Epoch  48500 , Cost:  nan\n",
      "Epoch  49000 , Cost:  nan\n",
      "Epoch  49500 , Cost:  nan\n",
      "Epoch  50000 , Cost:  nan\n",
      "Epoch  50500 , Cost:  nan\n",
      "Epoch  51000 , Cost:  nan\n",
      "Epoch  51500 , Cost:  nan\n",
      "Epoch  52000 , Cost:  nan\n",
      "Epoch  52500 , Cost:  nan\n",
      "Epoch  53000 , Cost:  nan\n",
      "Epoch  53500 , Cost:  nan\n",
      "Epoch  54000 , Cost:  nan\n",
      "Epoch  54500 , Cost:  nan\n",
      "Epoch  55000 , Cost:  nan\n",
      "Epoch  55500 , Cost:  nan\n",
      "Epoch  56000 , Cost:  nan\n",
      "Epoch  56500 , Cost:  nan\n",
      "Epoch  57000 , Cost:  nan\n",
      "Epoch  57500 , Cost:  nan\n",
      "Epoch  58000 , Cost:  nan\n",
      "Epoch  58500 , Cost:  nan\n",
      "Epoch  59000 , Cost:  nan\n",
      "Epoch  59500 , Cost:  nan\n",
      "Epoch  60000 , Cost:  nan\n",
      "Epoch  60500 , Cost:  nan\n",
      "Epoch  61000 , Cost:  nan\n",
      "Epoch  61500 , Cost:  nan\n",
      "Epoch  62000 , Cost:  nan\n",
      "Epoch  62500 , Cost:  nan\n",
      "Epoch  63000 , Cost:  nan\n",
      "Epoch  63500 , Cost:  nan\n",
      "Epoch  64000 , Cost:  nan\n",
      "Epoch  64500 , Cost:  nan\n",
      "Epoch  65000 , Cost:  nan\n",
      "Epoch  65500 , Cost:  nan\n",
      "Test data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainRBM(train[0], test[0], 50)#3000)\n",
    "\n",
    "# Need to investigate the unrolling/reshaping of nparrays to make sure that's happening in proper order.\n",
    "# Then need to investigate the learning -- first order is probably to fix the cost so that it displays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
